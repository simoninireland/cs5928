{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80cb2a0b",
   "metadata": {},
   "source": [
    "# Running epidemic simulations under `epyc` in parallel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15cc113",
   "metadata": {},
   "source": [
    "Having run simulations onew-at-a-time, in this notebooks we run several together in parallel. We do this by making use of the feature in `epyc` that leverages multicore processors, letting us run simulations on several cores. We'll then compare the performance of the two approaches in terms of the \"wallclock\" times of the two sets of experiments.\n",
    "\n",
    "When I present this notebook I'm using a laptop with only two cores, and so am limited to at most 2x speed-up. If you have access to a larger machine, change the parameters to use more cores: where and how to do this are clearly labelled. I typically do experimental work on a 16-core machine and use 12 of those cores for simulation, leaving 4 cores free for other things."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05d87a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy\n",
    "import numpy\n",
    "\n",
    "# data handling\n",
    "import pandas\n",
    "from pathlib import Path\n",
    "datasets = Path(\"../../datasets\")\n",
    "datasets.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# simulation\n",
    "from epyc import Experiment, Lab, ParallelLab, JSONLabNotebook\n",
    "from epydemic import ERNetwork, SIR, StochasticDynamics\n",
    "\n",
    "# plotting\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'png'\n",
    "matplotlib.rcParams['font.size'] = 10\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f97598",
   "metadata": {},
   "source": [
    "As usual, we'll stick to SIR simulation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b03fbd",
   "metadata": {},
   "source": [
    "## Setting up for comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc264a43",
   "metadata": {},
   "source": [
    "We'll first create a notebook with two result sets, one for sequential and one for parallel processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ed1640a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<epyc.resultset.ResultSet at 0x13f1fce10>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a lab notebook backed by a JSON file\n",
    "nb = JSONLabNotebook(Path(datasets, \"08-05-sir-seq-par.json\"), create=True)\n",
    "\n",
    "# add result sets\n",
    "nb.addResultSet(\"sir-seq\", \"Sequential simulations of SIR\")\n",
    "nb.addResultSet(\"sir-par\", \"Parallel (multicore) simulations of SIR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61c9777",
   "metadata": {},
   "source": [
    "## Sequential processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a404c8f",
   "metadata": {},
   "source": [
    "We'll assume we've already done the sequential experiment, so we can just grab the lab notebook holding the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42522a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the sequential results\n",
    "nbseq = JSONLabNotebook(Path(datasets, \"06-05-sir-seq.json\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918df242",
   "metadata": {},
   "source": [
    "Then we'll copy these results into the appropriate results set in our new notebook, so we only have to manage one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3eb85e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy result set\n",
    "nb.addResult(nbseq.results(), tag=\"sir-seq\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e311b71d",
   "metadata": {},
   "source": [
    "## Parallel processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f522b0",
   "metadata": {},
   "source": [
    "We now need a lab set for parallel processing. This is simply a matter of instanciating the `ParallelLab` class and telling it how many cores it should use. There are three ways to do this:\n",
    "\n",
    "- the default, which uses all the available cores\n",
    "- specify a number of cores with a positive number, such as 12\n",
    "- specify a number of cores *not* to use with a nagetive number, such as -4\n",
    "\n",
    "The last two will be the same on a 16-core machine.\n",
    "\n",
    "It doesn't do any good to exagerate the number of cores available, though: claiming to have 16 when you have 2 will actually make things slower! So first we should check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f67d5ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current system has 8 cores in total\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import cpu_count\n",
    "print(\"Current system has {c} cores in total\".format(c=cpu_count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a338025",
   "metadata": {},
   "source": [
    "This is the maximum number of cores it makes sense to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "823ad6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick the number of cores -- change this to change parallelism\n",
    "nCores = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62b3b37",
   "metadata": {},
   "source": [
    "We now create the lab and populate its parameter space as usual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "65ef0ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the lab\n",
    "lab = ParallelLab(notebook=nb, cores=nCores)\n",
    "\n",
    "# make sure the reuslts go into the right result set\n",
    "nb.select(\"sir-par\")\n",
    "\n",
    "# set the disease paramerter space\n",
    "lab[SIR.P_INFECTED] = 0.01\n",
    "lab[SIR.P_INFECT] = numpy.linspace(0.0, 1.0,\n",
    "                                   num=20)\n",
    "lab[SIR.P_REMOVE] = 0.002\n",
    "\n",
    "# set the topology for the generated network\n",
    "lab[ERNetwork.N] = int(1e4)\n",
    "lab[ERNetwork.KMEAN] = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4bc614",
   "metadata": {},
   "source": [
    "Then we run the experiment as usual &ndash; but this time in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e7ac57c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the experiment\n",
    "p = SIR()\n",
    "g = ERNetwork()\n",
    "e = StochasticDynamics(p, g)\n",
    "\n",
    "# run the experiment\n",
    "lab.runExperiment(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3bc059",
   "metadata": {},
   "source": [
    "The results seemed to be generated faster that time. How *much* faster depends on the number of cores you have available. We can determine this by extracting the total elapsed time from the two result sets and comparing them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e3173ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential 23s, Parallel 6s\n",
      "Speedup 4x on 6 cores\n"
     ]
    }
   ],
   "source": [
    "# grab the two datasets\n",
    "df_seq = nb.dataframe(tag=\"sir-seq\")\n",
    "df_par = nb.dataframe(tag=\"sir-par\")\n",
    "\n",
    "# compute the different wallclock total times\n",
    "wallclock_seq = (df_seq[Experiment.END_TIME].max() - df_seq[Experiment.END_TIME].min()).total_seconds()\n",
    "wallclock_par = (df_par[Experiment.END_TIME].max() - df_par[Experiment.END_TIME].min()).total_seconds()\n",
    "\n",
    "print(f\"Sequential {wallclock_seq:.0f}s, Parallel {wallclock_par:.0f}s\")\n",
    "print(\"Speedup {s:.0f}x on {c} cores\".format(s=wallclock_seq / wallclock_par,\n",
    "                                             c=lab.numberOfCores()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4ba758",
   "metadata": {},
   "source": [
    "It's worth noting that you *never* get what's sometimes called *perfect speed-up*, that is to say, a program that runs 12 times as fast on 12 cores. There is always some sequential overhead that slows things down. Getting 10x speed-up on 12 cores is impressive.\n",
    "\n",
    "The thing to note about the code above is how little it changes between sequential and parallel evaluation. This is because of the assumptions we make about the system: that every experiment is independent of every other, and so can run in parallel with it and in any order. It's perfectly possible to build experiments where this assumption is violated &ndash; for a simple example, think of an `Experiment` class with a class variable that's updated depending on which experiment runs when &ndash; in which case things will get ... interesting, and best avoided. The kind of parallelism that `epyc` supports is called *task parallelism*, and is very efficient when its asumptions are respected."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
