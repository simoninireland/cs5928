{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from multiprocessing import Pool\n",
    "\n",
    "from utilities import countdown, COUNT"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multithreading, Coroutines & Multiprocessing in Python \n",
    "\n",
    "In this notebook, we will look at some simple examples of multithreading, multiprocessing and asynchronous programs in Python. The execution time of each piece of code is out primary focus. We have a small utility file named `utilities.py` that contains a countdown function that we will use in the experiments, that decrements an integer until it reaches zero. \n",
    "\n",
    "First let us run a synchronous version of this function on a single thread and report the time in seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in seconds - 3.924863815307617\n"
     ]
    }
   ],
   "source": [
    "# single threaded program\n",
    "\n",
    "# start a timer\n",
    "start = time.time()\n",
    "\n",
    "# run the task\n",
    "countdown(COUNT)\n",
    "\n",
    "# end the timer and print execution time\n",
    "end = time.time()\n",
    "print('Time taken in seconds -', end - start)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will split this task over two threads by using the `threading` builtin module. To do this we create two `Thread()` instances whose target callable is our countdown function. We then split the work over the two threads evenly by getting each thread to count half of the integer `COUNT`. \n",
    "\n",
    "We start each thread's activity by calling the `start()` method on the `Thread` instances. We then call `join()`, which blocks until the thread returns. We might naively expect this to half the execution time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in seconds - 3.8616461753845215\n"
     ]
    }
   ],
   "source": [
    "# multithreaded program\n",
    "from threading import Thread\n",
    "\n",
    "\n",
    "# Create two thread objects and use them to invoke our countdown\n",
    "# function, splitting the count over each of them\n",
    "t1 = Thread(target=countdown, args=(COUNT//2,))\n",
    "t2 = Thread(target=countdown, args=(COUNT//2,))\n",
    "\n",
    "# start the timer\n",
    "start = time.time()\n",
    "\n",
    "# start the threads\n",
    "t1.start()\n",
    "t2.start()\n",
    "\n",
    "# block the calling thread until each thread terminates\n",
    "t1.join()\n",
    "t2.join()\n",
    "\n",
    "# end the timer and print the execution time\n",
    "end = time.time()\n",
    "print('Time taken in seconds -', end - start)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the execution time has not decreased as we expected, but has actually increased! From the lecture slides, we know this is due to the Global Interpreter Lock (GIL) preventing concurrent execution of the thread's activity. The small increase in execution time is due to the overheads in spawning new threads.\n",
    "\n",
    "Next we will try the multiprocessing builtin module to split the workload over new Python processes. To do this we create a `multiprocessing.Pool()` object and indicate how many processes we wish to use.\n",
    "\n",
    "We then map the callable `countdown` over iterable of the count chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in seconds - 1.9298930168151855\n"
     ]
    }
   ],
   "source": [
    "# multiprocessing program\n",
    "\n",
    "# start the timer\n",
    "start = time.time()\n",
    "\n",
    "# split the workload over multiple processes by creating a Pool object\n",
    "# with `num_processors` number of processes\n",
    "num_processors = 3\n",
    "p = Pool(processes = num_processors)\n",
    "\n",
    "# apply the task function to chunks of the total COUNT\n",
    "p.map(countdown, num_processors*[COUNT//num_processors])\n",
    "\n",
    "# end the timer\n",
    "end = time.time()\n",
    "\n",
    "print('Time taken in seconds -', end - start)   \n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike the multithreaded example, we can see that the execution time has significantly decreased meaning that the workload was indeed executed in parallel. We don't see linear speedups, likely due to the overheads of setting each process up allocating memory etc and gathering the results back to the main process."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Asynchronous programming with Python\n",
    "\n",
    "Asynchronous programming in Python is based on coroutines and uses the builtin `asyncio` module.\n",
    "\n",
    "The general architecture of async programming is to write small modular coroutines and one wrapper function that serves to chain each of the smaller coroutines together. In this example, we have a coroutine `f()` that sleeps for a random interval. It prints when it starts and when it returns.\n",
    "\n",
    "We then have a main function `g()` that calls `f()` a number of times.\n",
    "\n",
    "The first example is synchronous, each call of `f()` starts, sleeps and ends before the next one can start. This is quite slow, and our program doesn't do anything useful whilst it is waiting for each function to sleep. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Routine 0 is starting ...\n",
      "Routine 0 slept for 4s\n",
      "Routine 1 is starting ...\n",
      "Routine 1 slept for 1s\n",
      "Routine 2 is starting ...\n",
      "Routine 2 slept for 1s\n",
      "Routine 3 is starting ...\n",
      "Routine 3 slept for 3s\n",
      "Routine 4 is starting ...\n",
      "Routine 4 slept for 3s\n",
      "Time taken in seconds - 12.020970106124878\n"
     ]
    }
   ],
   "source": [
    "# synchronous programming in Python\n",
    "\n",
    "import random\n",
    "\n",
    "\n",
    "def f(i: int):\n",
    "    print(f\"Routine {i} is starting ...\")\n",
    "    sleep_time = random.randint(1,5)\n",
    "    time.sleep(sleep_time)\n",
    "    print(f\"Routine {i} slept for {sleep_time}s\")\n",
    "    return sleep_time\n",
    "\n",
    "\n",
    "def g():\n",
    "    r = [f(i) for i in range(5)]\n",
    "    return r\n",
    "\n",
    "\n",
    "# start the timer\n",
    "start = time.time()\n",
    "\n",
    "# call g()\n",
    "g()\n",
    "\n",
    "# end the timer\n",
    "end = time.time()\n",
    "\n",
    "print('Time taken in seconds -', end - start)   "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the second example we will make use of asynchronous programming in Python by declaring the functions to be coroutines with the `async` signature and declaring when we want to switch context with the `await` keyword\n",
    "\n",
    "```Python\n",
    "async def g():\n",
    "    # Pause execution of g() here and come back when f() has finished\n",
    "    r = await f()\n",
    "    return r\n",
    "```\n",
    "\n",
    "We define a function `g()` below to gather the tasks by mapping the central coroutine `f()` across an iterable. (In Python scripts, we can ignore the `nest_asyncio.apply()` line, as this is in order to use asyncio in Jupyter notebooks.)\n",
    "\n",
    "Note all functions should be declared `async`, we shouldn't call synchronous functions from async functions as a general design principle. If any parts of the codebase are blocking functions, then they will grab hold of the execution and ruin the asynchronous desing pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coroutine 0 is starting ...\n",
      "Coroutine 1 is starting ...\n",
      "Coroutine 2 is starting ...\n",
      "Coroutine 3 is starting ...\n",
      "Coroutine 4 is starting ...\n",
      "Coroutine 1 slept for 1s\n",
      "Coroutine 3 slept for 1s\n",
      "Coroutine 0 slept for 4s\n",
      "Coroutine 2 slept for 4s\n",
      "Coroutine 4 slept for 5s\n",
      "Time taken in seconds - 5.002790927886963\n"
     ]
    }
   ],
   "source": [
    "# asynchronous programming in Python\n",
    "\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "\n",
    "\n",
    "async def f(i: int):\n",
    "    print(f\"Coroutine {i} is starting ...\")\n",
    "    sleep_time = random.randint(1,5)\n",
    "    await asyncio.sleep(sleep_time)\n",
    "    print(f\"Coroutine {i} slept for {sleep_time}s\")\n",
    "    return sleep_time\n",
    "\n",
    "\n",
    "async def g():\n",
    "    r = await asyncio.gather(*(f(i) for i in range(5)))\n",
    "    return r\n",
    "\n",
    "\n",
    "# Enable nested asyncio event loop as we are running in a Jupyter notebook\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# start the timer\n",
    "start = time.time()\n",
    "\n",
    "# call g() asynchronously\n",
    "asyncio.run(g())\n",
    "\n",
    "# end the timer\n",
    "end = time.time()\n",
    "\n",
    "print('Time taken in seconds -', end - start)   "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that it didn't take long for the asynchronous version to return, this is because instead of waitiing idly on each sleep, the coroutines passed the context back to the main calling coroutine `g()` and allowed it to carry on its execution. We can see that the other calls of `f()` start before the first ends. \n",
    "\n",
    "# Subprocesses\n",
    "\n",
    "The subprocesses builtin module allows you to run new programs and scripts by spawning a processes from inside a Python program. It uses Pipes to connect to the standard output and error streams as well as gathering return codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'COUNT = 100000000\\n\\ndef countdown(n):\\n    while n>0:\\n        n -= 1'\n"
     ]
    }
   ],
   "source": [
    "# An example of the subprocesses module\n",
    "\n",
    "from subprocess import Popen, PIPE\n",
    "\n",
    "\n",
    "# Create a Popen instance, passing command line arguments and piping the output streams\n",
    "# In this case, we want to read the contents of the `utilities.py` file to standard output.\n",
    "process = Popen(['cat','utilities.py'], stdout=PIPE, stderr=PIPE)\n",
    "\n",
    "# communicate with the process and obtain standard output and error streams\n",
    "stdout, stderr = process.communicate()\n",
    "\n",
    "# print the standard output string\n",
    "print(stdout)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3104",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
